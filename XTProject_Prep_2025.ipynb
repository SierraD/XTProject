{
 "cells": [
  {
   "cell_type": "raw",
   "id": "a72278b0-738f-42d0-bc27-a5cfa92ec0f9",
   "metadata": {},
   "source": [
    "\"\"\" This file is part of the XTProject software\n",
    "    File author(s): Sierra Dean <ccnd@live.com>\n",
    "    source: https://github.com/SierraD/XTProject\n",
    "    Last Updated: January 29 2025\n",
    "\n",
    "    Changed spelling of \"Miscellaneous\" in XT Data section\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17442c79-5e64-4fce-b47b-82d7341b06c1",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06a96521-2ab0-448d-bd0a-1bffbd65bec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5eb6c31-a9b5-473e-9cc8-b4c2cf164486",
   "metadata": {},
   "source": [
    "# Obtain the XT Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8027316-17ab-4881-80bc-630b6b3f0e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Designate the path to the directory containing all XT Page code files\n",
    "path_XTP = \"C:\\\\Users\\\\sdean\\\\Desktop\\\\Sierra Code\\\\XTP_Directory\\\\\"\n",
    "files_XTP = [file for file in os.listdir(path_XTP)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55e895fe-423c-42c0-886c-4317979a7f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dataframe to be used for information from all XT Page source files\n",
    "All_XTP = pd.DataFrame(dtype=object)\n",
    "# Perform this looped operation for each file in the directory\n",
    "for file in files_XTP:\n",
    "    # Read the XT Page code files\n",
    "    d = pd.read_csv(path_XTP+file, header=None)\n",
    "    df = pd.DataFrame(data=d, dtype=object)\n",
    "    df = df.rename(columns={df.columns[0]:\"Text\"})\n",
    "    # Remove all \"Internal Information\" markers, which disrupt the information capture\n",
    "    bad_index = [\"internalRead\", \"internal read\", \"INternal Read\", \"--\", \"param\", \"cmcmem_word\"]\n",
    "    for bad in bad_index:\n",
    "        ind = df[df[\"Text\"].str.contains(bad)].index\n",
    "        df = df.drop(index=ind, axis=0)\n",
    "        df = df.reset_index(drop=True)\n",
    "    # Create the Thumbwheel and XT Page dataframe columns\n",
    "    df[\"Thumbwheel\"] = \"N/A\"\n",
    "    df[\"XT Page\"] = file\n",
    "    # Remove all rows which arent a Thumbwheel name or designation\n",
    "    for i in df[\"Text\"].index:\n",
    "        if \"//\" not in df[\"Text\"][i]:\n",
    "            if \"ccs\" not in df[\"Text\"][i]:\n",
    "                df = df.drop(index=i, axis=0)\n",
    "    df = df.reset_index(drop=True)\n",
    "    # Move the Thumbwheel designations to their own column\n",
    "    for j in df[\"Text\"].index:\n",
    "        if \"ccs\" in df[\"Text\"][j]:\n",
    "            df.loc[j-1, \"Thumbwheel\"] = df[\"Text\"][j]\n",
    "    # Remove all rows which don't have a working Thumbwheel designation\n",
    "    for k in df[\"Text\"].index:\n",
    "        if \"N/A\" in df[\"Thumbwheel\"][k]:\n",
    "            df = df.drop(index=k, axis=0)\n",
    "    # Append the dataframe created for this file to a dataframe of all files in the directory         \n",
    "    All_XTP = pd.concat([All_XTP, df], axis=0)\n",
    "    All_XTP = All_XTP.reset_index(drop=True)\n",
    "# Format the dataframe\n",
    "All_XTP[\"Text\"] = All_XTP[\"Text\"].str.upper()\n",
    "All_XTP[\"Text\"] = All_XTP[\"Text\"].str.replace(\"//\", \"\")\n",
    "All_XTP[\"Text\"] = All_XTP[\"Text\"].str.replace(\"\\t\", \"\")\n",
    "All_XTP[\"Text\"] = All_XTP[\"Text\"].str.strip()\n",
    "All_XTP[\"Thumbwheel\"] = All_XTP[\"Thumbwheel\"].str.replace(\"ccs\", \"\")\n",
    "All_XTP[\"Thumbwheel\"] = All_XTP[\"Thumbwheel\"].str.replace(\"\\t\", \"\")\n",
    "All_XTP[\"Thumbwheel\"] = All_XTP[\"Thumbwheel\"].str.replace('\"', \"\")\n",
    "All_XTP[\"Thumbwheel\"] = All_XTP[\"Thumbwheel\"].str.strip()\n",
    "All_XTP[\"XT Page\"] = All_XTP[\"XT Page\"].str.replace(\".txt\", \"\")\n",
    "All_XTP[\"XT Page\"] = All_XTP[\"XT Page\"].str.replace(\"XTP_\", \" \")\n",
    "All_XTP[\"XT Page\"] = All_XTP[\"XT Page\"].str.strip()\n",
    "# Designate the naming convention for the Thumbwheel systems\n",
    "Key_TW = [\"B1\", \"V1\", \"2A\", \"2V\", \"B2\", \"B4\", \"V4\", \"CD\", \"DG\", \"ET\", \"I1\", \"I2\", \"PV\", \"I3\", \"CV\", \"I4\", \"EV\", \"LS\", \"IB\", \"IV\", \"MG\", \n",
    "        \"MS\", \"PT\", \"RF\", \"SB\", \"SF\", \"TG\", \"TK\", \"TV\"]\n",
    "Key_Search = [\"Beamline 1\", \"Beamline 1 Vacuum\", \"Beamline 2A\", \"Beamline 2A Vacuum\", \"Beamline 2C\", \"Beamline 4\", \"Beamline 4 Vacuum\", \n",
    "              \"CAMAC Design\", \"Diagnostics\", \"Extra Thumbwheels\", \"Ion Source 1\", \"Ion Source 2\", \"Ion Source 2 Vacuum\", \"Ion Source 3\", \n",
    "              \"Ion Source 3 Vacuum\", \"Ion Source 4\", \"Ion Source 4 Vacuum\", \"Ion Source 4 Laser\", \"ISIS Beamline\", \"ISIS Beamline Vacuum\", \n",
    "              \"Magnets\", \"Miscellaneous\", \"Proton Therapy\", \"Radio Frequency\", \"Secondary Beamlines\", \"Safety\", \"Targets\", \"Tank\", \"Tank Vacuum\"]\n",
    "# Remove all Thumbwheels that are not in the systems\n",
    "Bad_df = All_XTP\n",
    "for l in range(0, len(Key_TW)):\n",
    "    indexes = Bad_df[Bad_df[\"Thumbwheel\"].str.contains(Key_TW[l])].index\n",
    "    Bad_df = Bad_df.drop(indexes, axis=0)\n",
    "All_XTP = All_XTP.drop(Bad_df.index, axis=0)\n",
    "All_XTP = All_XTP.reset_index(drop=True)\n",
    "# Create a column in the dataframe for the Thumbwheel systems\n",
    "All_XTP[\"System\"] = \"N/A\"\n",
    "for m in range(0, len(Key_TW)):\n",
    "    Key_Indexes = All_XTP[All_XTP[\"Thumbwheel\"].str.contains(Key_TW[m])].index\n",
    "    All_XTP.loc[Key_Indexes, \"System\"] = Key_Search[m]\n",
    "# Identify each unique instance of repeated thumbwheels found on multiple pages\n",
    "Drop_All = []\n",
    "Duplicates = All_XTP[(All_XTP[\"Thumbwheel\"].duplicated() == True)]\n",
    "Duplicate_TWs = list(np.unique(Duplicates[\"Thumbwheel\"]))\n",
    "# Group together all the thumbwheel information from each page\n",
    "for n in Duplicate_TWs:\n",
    "    indexes = []\n",
    "    for o in range(0, len(All_XTP[\"Thumbwheel\"])):\n",
    "        if All_XTP[\"Thumbwheel\"][o] == n:\n",
    "            indexes.append(o)\n",
    "    Duplicate_Titles = str(list(np.unique(All_XTP[\"Text\"].loc[indexes])))\n",
    "    Duplicate_XTPs = str(list(np.unique(All_XTP[\"XT Page\"].loc[indexes])))\n",
    "    All_XTP.loc[indexes[0], \"Text\"] = Duplicate_Titles\n",
    "    All_XTP.loc[indexes[0], \"XT Page\"] = Duplicate_XTPs\n",
    "    a = indexes.pop(0)\n",
    "    for p in indexes:\n",
    "        Drop_All.append(p)\n",
    "# Removed all duplicated instances so each thumbwheel only appears in the dataframe once\n",
    "All_XTP = All_XTP.drop(Drop_All, axis=0)\n",
    "All_XTP = All_XTP.reset_index(drop=True)\n",
    "# Remove thumbwheels no longer in use\n",
    "indexe = All_XTP[All_XTP[\"Thumbwheel\"].str.contains(\"//\")].index\n",
    "All_XTP = All_XTP.drop(index=indexe, axis=0)\n",
    "All_XTP = All_XTP.reset_index(drop=True)\n",
    "# Format the dataframe\n",
    "All_XTP[\"Text\"] = All_XTP[\"Text\"].str.replace(\"[\", \"\")\n",
    "All_XTP[\"Text\"] = All_XTP[\"Text\"].str.replace(\"]\", \"\")\n",
    "All_XTP[\"Text\"] = All_XTP[\"Text\"].str.replace(\"'\", \"\")\n",
    "All_XTP[\"XT Page\"] = All_XTP[\"XT Page\"].str.replace(\"[\", \"\")\n",
    "All_XTP[\"XT Page\"] = All_XTP[\"XT Page\"].str.replace(\"]\", \"\")\n",
    "All_XTP[\"XT Page\"] = All_XTP[\"XT Page\"].str.replace(\"'\", \"\")\n",
    "# This results in a dataframe containing all active thumbwheels, their associated text,\n",
    "# their associated system, and the XT Pages they exist on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d60ab980-826b-4133-b26a-790dfe10c01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(All_XTP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387f1266-56fe-4a8e-93b9-c5428cd2de5c",
   "metadata": {},
   "source": [
    "# Obtain the Scan Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a678eb0f-c4c7-48a8-b245-a1edb66085cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Designate the path to the directory containing all Scan source files\n",
    "path_Scan = \"C:\\\\Users\\\\sdean\\\\Desktop\\\\Sierra Code\\\\Scan_Directory\\\\\"\n",
    "files_Scan = [file for file in os.listdir(path_Scan)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0c7f946-4878-4df0-9dc5-68e822ef0662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dataframe to be used for information from all scans\n",
    "All_Scans = pd.DataFrame(columns = [\"Scan\", \"Element\", \"On Action\", \"DO OFF Command\", \"DO MESSAGE Command\", \"DO WRITE Command\", \n",
    "                                    \"DO INSERT Command\", \"DO CALC Command\", \"DO LOG Command\", \"DO CLEAR Command\"], dtype=object)\n",
    "# Perform this looped operation for each file in the directory\n",
    "for file in files_Scan:\n",
    "    # Create an empty dataframe to be re-used for each file \n",
    "    df_scan = pd.DataFrame(index=[0], columns = [\"Scan\", \"Element\", \"On Action\", \"DO OFF Command\", \"DO MESSAGE Command\", \"DO WRITE Command\", \n",
    "                                             \"DO INSERT Command\", \"DO CALC Command\", \"DO LOG Command\", \"DO CLEAR Command\"], dtype=object)\n",
    "    # Read the Scan source files\n",
    "    ds = pd.read_csv(path_Scan+file, header=None)\n",
    "    dfs = pd.DataFrame(data=ds, dtype=str)\n",
    "    dfs = dfs.rename(columns={dfs.columns[0]:\"Scan\"})\n",
    "    # Remove all \"Internal Information\" markers, which disrupt the information capture \n",
    "    comments = dfs[dfs[\"Scan\"].str.contains(\"//\")].index\n",
    "    dfs = dfs.drop(comments, axis=0)\n",
    "    dfs = dfs.reset_index(drop=True)\n",
    "    freq = dfs[dfs[\"Scan\"].str.contains(\"FREQUENCY:\")].index\n",
    "    dfs = dfs.drop(freq, axis=0)\n",
    "    dfs = dfs.reset_index(drop=True)\n",
    "    peri = dfs[dfs[\"Scan\"].str.contains(\"PERIOD:\")].index\n",
    "    dfs = dfs.drop(peri, axis=0)\n",
    "    dfs = dfs.reset_index(drop=True)\n",
    "    numel = dfs[dfs[\"Scan\"].str.contains(\"NUMBER OF ELEMENTS:\")].index\n",
    "    dfs = dfs.drop(numel, axis=0)\n",
    "    dfs = dfs.reset_index(drop=True)\n",
    "    disac = dfs[dfs[\"Scan\"].str.contains(\"ON DISABLED ACTIONS:\")].index\n",
    "    dfs = dfs.drop(disac, axis=0)\n",
    "    dfs = dfs.reset_index(drop=True)\n",
    "    trueac = dfs[dfs[\"Scan\"].str.contains(\"ON TRUE ACTIONS:\")].index\n",
    "    dfs = dfs.drop(trueac, axis=0)\n",
    "    dfs = dfs.reset_index(drop=True)\n",
    "    # Separate the code blocks into the scan element and relevant commands\n",
    "    count = -1\n",
    "    for q in dfs[\"Scan\"].index:\n",
    "        if \"ELEMENT\" in dfs[\"Scan\"][q]:\n",
    "            count += 1\n",
    "            df_scan.loc[count, \"Element\"] = dfs[\"Scan\"][q]\n",
    "        elif \"DO OFF\" in dfs[\"Scan\"][q]:\n",
    "            if pd.isna(df_scan.at[count, \"DO OFF Command\"]) == False:\n",
    "                df_scan.loc[count, \"DO OFF Command\"] = df_scan.loc[count, \"DO OFF Command\"] + \", \" + dfs[\"Scan\"][q]\n",
    "            else:\n",
    "                df_scan.loc[count, \"DO OFF Command\"] = dfs[\"Scan\"][q]\n",
    "        elif \"DO MESSAGE\" in dfs[\"Scan\"][q]:\n",
    "            df_scan.loc[count, \"DO MESSAGE Command\"] = dfs[\"Scan\"][q]\n",
    "        elif \"DO WRITE\" in dfs[\"Scan\"][q]:\n",
    "            if pd.isna(df_scan.at[count, \"DO WRITE Command\"]) == False:\n",
    "                df_scan.loc[count, \"DO WRITE Command\"] = df_scan.loc[count, \"DO WRITE Command\"] + \", \" + dfs[\"Scan\"][q]\n",
    "            else:\n",
    "                df_scan.loc[count, \"DO WRITE Command\"] = dfs[\"Scan\"][q]\n",
    "        elif \"DO INSERT\" in dfs[\"Scan\"][q]:\n",
    "            df_scan.loc[count, \"DO INSERT Command\"] = dfs[\"Scan\"][q]\n",
    "        elif \"DO CALC\" in dfs[\"Scan\"][q]:\n",
    "            if pd.isna(df_scan.at[count, \"DO CALC Command\"]) == False:\n",
    "                df_scan.loc[count, \"DO CALC Command\"] = df_scan.loc[count, \"DO CALC Command\"] + \", \" + dfs[\"Scan\"][q]\n",
    "            else:\n",
    "                df_scan.loc[count, \"DO CALC Command\"] = dfs[\"Scan\"][q]\n",
    "        elif \"DO LOG\" in dfs[\"Scan\"][q]:\n",
    "            df_scan.loc[count, \"DO LOG Command\"] = dfs[\"Scan\"][q]\n",
    "        elif \"DO CLEAR\" in dfs[\"Scan\"][q]:\n",
    "            df_scan.loc[count, \"DO CLEAR Command\"] = dfs[\"Scan\"][q]\n",
    "        else:\n",
    "            if pd.isna(df_scan.at[count, \"On Action\"]) == False:\n",
    "                df_scan.loc[count, \"On Action\"] = df_scan.loc[count, \"On Action\"] + \", \" + dfs[\"Scan\"][q]\n",
    "            else:\n",
    "                df_scan.loc[count, \"On Action\"] = dfs[\"Scan\"][q]\n",
    "    # Append the dataframe created for this file to a dataframe of all files in the directory \n",
    "    df_scan[\"Scan\"] = file\n",
    "    All_Scans = pd.concat([All_Scans, df_scan], axis=0)\n",
    "    All_Scans = All_Scans.reset_index(drop=True)\n",
    "# Removed all the Elements that are disabled\n",
    "disab = All_Scans[All_Scans[\"Element\"].str.contains('DISABLED')].index\n",
    "All_Scans = All_Scans.drop(disab, axis=0)\n",
    "All_Scans = All_Scans.reset_index(drop=True)\n",
    "for r in All_Scans[\"Element\"].index:\n",
    "    All_Scans.loc[r, \"Element\"] = All_Scans[\"Element\"][r].split(\":\")[0]\n",
    "All_Scans[\"Element\"] = All_Scans[\"Element\"].str.replace(\"ELEMENT \", \"\")\n",
    "# Format the dataframe\n",
    "All_Scans[\"Scan\"] = All_Scans[\"Scan\"].str.replace(\"_Scan.csv\", \"\")\n",
    "All_Scans = All_Scans.fillna('N/A')\n",
    "# Format the Thumbwheels from SYS,NUM,ID to SYS NUM ID, as it is printed in the other files\n",
    "for s in All_Scans.columns:\n",
    "    All_Scans[s] = All_Scans[s].str.replace(\", \", \"!!!\") \n",
    "    All_Scans[s] = All_Scans[s].str.replace(\",\", \" \")\n",
    "    All_Scans[s] = All_Scans[s].str.replace(\"!!!\", \", \") \n",
    "# Format the Message Commands to remove symbols \n",
    "All_Scans[\"DO MESSAGE Command\"] = All_Scans[\"DO MESSAGE Command\"].str.replace(\"mainlog \", \"\")\n",
    "All_Scans[\"DO MESSAGE Command\"] = All_Scans[\"DO MESSAGE Command\"].str.replace(\"opslog \", \"\") \n",
    "All_Scans[\"DO MESSAGE\"] = All_Scans[\"DO MESSAGE Command\"]\n",
    "All_Scans[\"DO MESSAGE Command\"] = All_Scans[\"DO MESSAGE Command\"].str.strip()\n",
    "symb = All_Scans[All_Scans[\"DO MESSAGE Command\"].str.contains('\"')].index\n",
    "for t in symb:\n",
    "    All_Scans[\"DO MESSAGE Command\"][t] = All_Scans[\"DO MESSAGE Command\"][t].split('\"')[0]\n",
    "# This results in a dataframe containing all scans, their associated elements, the initial\n",
    "# action which promts the scan response, and all resulting actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "135e7c3d-6337-4eae-8a4a-d3f66da9282a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(All_Scans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d330b8d-9ee2-49c3-8642-caac0952493a",
   "metadata": {},
   "source": [
    "# Associate Thumbwheels with Scan Elements\n",
    "Cell must be run twice to overcome the error; Known issue, does not affect outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88d183fa-6ce8-4c4d-a635-12c904740373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the thumbwheels in the scan data\n",
    "for u in range(0, len(All_XTP[\"Thumbwheel\"])):\n",
    "    ind = [All_Scans[All_Scans[col].str.contains(All_XTP[\"Thumbwheel\"][u])].index for col in All_Scans]\n",
    "    merged_ind = list(itertools.chain.from_iterable(ind))\n",
    "    # Record the scan and the element which contain each Thumbwheel\n",
    "    scan = [] \n",
    "    element = []\n",
    "    if len(merged_ind) != 0:\n",
    "        count = 0\n",
    "        for v in merged_ind:\n",
    "            if All_Scans[\"Scan\"][v] not in scan:\n",
    "                scan.append(All_Scans[\"Scan\"][v])\n",
    "                element.insert(count, [str(All_Scans[\"Scan\"][v])]) \n",
    "                element[count].append(int(All_Scans[\"Element\"][v])) \n",
    "                count += 1\n",
    "            else:\n",
    "                element[count-1].append(int(All_Scans[\"Element\"][v]))\n",
    "    # Append the scan and element information to the dataframe for all XT data \n",
    "    if len(scan) != 0:        \n",
    "        All_XTP.at[u, \"Scan\"] = scan\n",
    "        All_XTP.at[u, \"Scan Element\"] = element\n",
    "All_XTP[\"Scan\"] = All_XTP[\"Scan\"].apply(lambda d: d if isinstance(d, list) else \"N/A\")\n",
    "All_XTP[\"Scan Element\"] = All_XTP[\"Scan Element\"].apply(lambda d: d if isinstance(d, list) else \"N/A\")\n",
    "# This adds to the dataframe containing all active thumbwheels, their associated text,\n",
    "# their associated system, and the XT Pages they exist on, adding their associated scans \n",
    "# and scan elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d71b0922-1e5b-4fd1-901d-bcfa3954ae78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(All_XTP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc66e41-01e3-4285-85d6-2d426e468898",
   "metadata": {},
   "source": [
    "# Obtain the Interlock Statement Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d126ad22-9b0a-4384-8c58-bd0466a0725d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Designate the path to the directory containing all Interlock source files\n",
    "path_I = \"C:\\\\Users\\\\sdean\\\\Desktop\\\\Sierra Code\\\\Scan_ILStat\\\\\"\n",
    "files_I = [file for file in os.listdir(path_I)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01b74a6d-b902-4b39-8f20-60f9751a27c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dataframe to be used for the interlock statements from all files\n",
    "All_IL = pd.DataFrame(columns = [\"Scan\", \"ELT #\", \"I/L Statement\", \"Message log message printed\"], dtype=str)\n",
    "# Perform this looped operation for each file in the directory\n",
    "for file in files_I:\n",
    "    # Read the Interlock source files\n",
    "    di = pd.read_csv(path_I+file, skiprows=4, dtype=str)\n",
    "    # Create an empty dataframe to be re-used for each file \n",
    "    ddi = pd.DataFrame(data=di, columns=([\"ELT #\", \"I/L Statement\", \"Message log message printed\"]))\n",
    "    ddi = ddi.dropna(how=\"all\")\n",
    "    ddi = ddi.reset_index(drop=True)\n",
    "    ddi[\"Scan\"] = file\n",
    "    # Append the dataframe created for this file to a dataframe of all files in the directory \n",
    "    All_IL = pd.concat([All_IL, ddi])\n",
    "    All_IL = All_IL.reset_index(drop=True)\n",
    "# Format the dataframe\n",
    "All_IL[\"Scan\"] = All_IL[\"Scan\"].str.replace(\".csv\", \"\")\n",
    "All_IL = All_IL.rename(columns={\"ELT #\": \"Element\", \"Message log message printed\":\"CCS Message\"}, inplace=False)\n",
    "# Remove any disabled messages\n",
    "All_IL = All_IL.fillna('N/A')\n",
    "dis = All_IL[All_IL[\"I/L Statement\"].str.contains(\"Disabled\")].index\n",
    "All_IL = All_IL.drop(dis, axis=0)\n",
    "# Format the dataframe\n",
    "All_IL[\"Scan\"] = All_IL[\"Scan\"].str.replace(\"_MSG\", \"\")\n",
    "All_IL = All_IL.reset_index(drop=True)\n",
    "# This results in a dataframe containing all scans, scan elements,\n",
    "# their associated interlock statements, and the resulting \n",
    "# CCS message printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb28116c-aaf1-451c-8611-070772604585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(All_IL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd76c22-789d-4dbd-b6b8-5d382371a6fc",
   "metadata": {},
   "source": [
    "# Associate Interlock Statements with Scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f005c0a0-2bec-4873-9793-b82633d33346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search through each scan element with an associated interlock statement\n",
    "for w in All_IL.index:\n",
    "    IL_Scan = All_IL[\"Scan\"][w]\n",
    "    IL_Element = All_IL[\"Element\"][w]\n",
    "    IL_Interlock = All_IL[\"I/L Statement\"][w]\n",
    "    IL_CCS = All_IL[\"CCS Message\"][w]\n",
    "    # Append the interlock and ccs message to the original scan dataframe\n",
    "    Both_Scans = All_Scans[All_Scans[\"Scan\"]==IL_Scan].index\n",
    "    Both_Elements = All_Scans[All_Scans[\"Element\"]==IL_Element].index\n",
    "    common = list(set(Both_Scans) & set(Both_Elements))\n",
    "    if len(common) != 0:\n",
    "        All_Scans.loc[common[0], \"I/L Statement\"] = IL_Interlock\n",
    "        All_Scans.loc[common[0], \"CCS Message\"] = IL_CCS\n",
    "# Format the dataframe\n",
    "All_Scans = All_Scans.fillna('N/A')\n",
    "# This adds to the dataframe containing all scans, their associated elements, \n",
    "# the initial action which promts the scan response, and all resulting actions, \n",
    "# adding their associated interlock statement and CCS messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "34e778c9-8ce6-4750-b974-2729f0156b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(All_Scans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a573ce-27e2-4475-b614-ffc51a8dfb4e",
   "metadata": {},
   "source": [
    "# Obtain the Messages Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0741ad74-e0da-4107-bc0e-1ee38def166c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Designate the path to the directory containing the Message file\n",
    "path_M = \"C:\\\\Users\\\\sdean\\\\Desktop\\\\Sierra Code\\\\MES2.csv\"\n",
    "# Read the Messages source file\n",
    "dm = pd.read_csv(path_M, dtype=str, header=None)\n",
    "# Create an dataframe containing the Message number and associated message\n",
    "ddm = pd.DataFrame(data=dm)\n",
    "ddm = ddm.rename(columns={0: \"First\"})\n",
    "ddm[['Message Number', 'Message']] = ddm['First'].str.split(' ', n=1, expand=True)\n",
    "ddm = ddm.drop(['First'], axis=1)\n",
    "ddm['Message Number'] = ddm['Message Number'].str.strip()\n",
    "ddm['Message'] = ddm['Message'].str.strip()\n",
    "# This results in a dataframe containing Message numbers and their\n",
    "# associated Message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "48d36c99-e86c-410e-a495-d3b430a8ac55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(ddm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650640a7-fe63-4f9b-b8a9-0543599b5652",
   "metadata": {},
   "source": [
    "# Associate Output Message with Scan DO MESSAGE Command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "08681e1d-4503-40aa-a142-8a0f9a64ebce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine all Scans which contain a Message Number\n",
    "Mes_list = All_Scans[\"DO MESSAGE Command\"]\n",
    "Nas = All_Scans[All_Scans[\"DO MESSAGE Command\"]==\"N/A\"].index\n",
    "# Create a list of all Message numbers which need an associated Message\n",
    "Mes_list = Mes_list.drop(index=Nas)\n",
    "Mes_list = Mes_list.str.replace(\"DO MESSAGE\", \"\")\n",
    "Mes_list = Mes_list.str.strip()\n",
    "# Append the Message Number and Message to the original scan dataframe\n",
    "for x in range(0, len(Mes_list.index)):\n",
    "    Place = ddm[ddm[\"Message Number\"]==(Mes_list[Mes_list.index[x]])].index\n",
    "    a = ddm[\"Message Number\"][Place[0]]\n",
    "    b = All_Scans[\"DO MESSAGE\"][Mes_list.index[x]]\n",
    "    b = b.replace(\"DO MESSAGE \"+a, \"\")\n",
    "    c = ddm[\"Message\"][Place[0]]\n",
    "    All_Scans.loc[Mes_list.index[x], \"DO MESSAGE\"] = \"DO MESSAGE \"+a+\": \"+c+b\n",
    "# Format the dataframe\n",
    "All_Scans[\"DO MESSAGE\"] = All_Scans[\"DO MESSAGE\"].str.replace('\"', \"\")\n",
    "# This adds to the dataframe containing all scans, their associated elements, \n",
    "# the initial action which promts the scan response, and all resulting actions, \n",
    "# adding the full message printed when a scan action is triggered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "05062169-2e56-41bb-8b05-a10fe2808cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(All_Scans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac271adc-e2ed-4723-b1d4-3ceb1b468e70",
   "metadata": {},
   "source": [
    "# Save the Resulting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8b226f68-d18c-4708-849d-4a1c15e55bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the ANSI color code before saving the data\n",
    "All_Scans[\"DO MESSAGE\"] = All_Scans[\"DO MESSAGE\"].str.replace(\"\\033[31m\", \"\") \n",
    "All_Scans[\"DO MESSAGE\"] = All_Scans[\"DO MESSAGE\"].str.replace(\"\\033[33m\", \"\") \n",
    "All_Scans[\"DO MESSAGE\"] = All_Scans[\"DO MESSAGE\"].str.replace(\"[1m[33m\", \"\") \n",
    "\n",
    "# Save the data\n",
    "# All_XTP.to_csv('XTP_2025.csv', index=False)\n",
    "# All_Scans.to_csv('SCNS_2025.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
